# ZDX Configuration
#
# This file is auto-generated. Edit as needed.
# Documentation: https://github.com/tallesborges/zdx#configuration

# The Claude model to use
model = "claude-haiku-4-5"

# Maximum tokens for responses (optional)
# Defaults to the model's output limit (exclusive, minus 1) when unset.
# max_tokens = 12288

# Timeout for tool execution in seconds (0 disables timeout)
tool_timeout_secs = 0

# System prompt (inline)
# system_prompt = "You are a helpful coding assistant."

# System prompt from file (takes precedence over inline)
# system_prompt_file = "/path/to/system_prompt.md"

# Extended thinking level
# Controls how much reasoning the model shows before responding.
# Higher levels allocate more output tokens to reasoning.
# Options: off, minimal (~5%), low (~20%), medium (~50%), high (~80%), xhigh (~95%)
# Note: when max_tokens is set, it is auto-adjusted to ensure room for both thinking and response.
thinking_level = "off"

# Model used for handoff generation subagent.
# Examples: "gemini-cli:gemini-2.5-flash", "openai:gpt-5.2"
# handoff_model = "gemini-cli:gemini-2.5-flash"

# Model used for auto-title generation subagent.
# Examples: "gemini-cli:gemini-2.5-flash", "openai:gpt-5.2"
# title_model = "gemini-cli:gemini-2.5-flash"

# OpenAI reasoning effort (used by Codex models).
# Options: low, medium, high, xhigh

# Provider configuration.
# api_key: Optional API key (overrides environment variable)
# base_url: Optional base URL (for proxies or test rigs)
# tools: List of enabled tools (default varies by provider)
#
# Available tools: bash, apply_patch, edit, read, write
# Default tool sets:
#   - Most providers: ["bash", "edit", "read", "write"]
#   - OpenAI Codex:   ["bash", "apply_patch", "read"]

[providers.anthropic]
enabled = true
# api_key = "sk-ant-..."  # Overrides ANTHROPIC_API_KEY env var
# base_url = "https://api.anthropic.com"
models = ["claude-opus-4-5", "claude-sonnet-4-5", "claude-haiku-4-5"]
tools = ["bash", "edit", "read", "write"]

[providers.claude_cli]
enabled = true
# base_url = "https://api.anthropic.com"
models = ["claude-opus-4-5", "claude-sonnet-4-5", "claude-haiku-4-5"]
tools = ["bash", "edit", "read", "write"]

[providers.openai]
enabled = true
# api_key = "sk-..."  # Overrides OPENAI_API_KEY env var
# base_url = "https://api.openai.com/v1"
models = ["gpt-5.2", "gpt-5-mini", "gpt-5-nano", "gpt-5.1-codex", "gpt-5.1-codex-max", "gpt-5.1-codex-mini", "gpt-4.1"]
tools = ["bash", "edit", "read", "write"]

[providers.openai_codex]
enabled = true
models = ["gpt-5.2-codex", "gpt-5.1-codex-max", "gpt-5.1-codex-mini", "gpt-5.2"]
# Codex models have built-in apply_patch instructions
tools = ["bash", "apply_patch", "read"]

[providers.openrouter]
enabled = true
# api_key = "sk-or-..."  # Overrides OPENROUTER_API_KEY env var
# base_url = "https://openrouter.ai/api/v1"
models = ["*:exacto"]
tools = ["bash", "edit", "read", "write"]

[providers.gemini]
enabled = true
# api_key = "..."  # Overrides GEMINI_API_KEY env var
# base_url = "https://generativelanguage.googleapis.com/v1beta"
models = ["gemini-3-flash-preview", "gemini-3-pro-preview", "gemini-2.5-flash", "gemini-2.5-flash-lite"]
tools = ["bash", "edit", "read", "write"]

[providers.gemini_cli]
enabled = true
# base_url = "https://cloudcode-pa.googleapis.com"
models = ["gemini-3-flash-preview", "gemini-3-pro-preview", "gemini-2.5-flash", "gemini-2.5-flash-lite"]
tools = ["bash", "edit", "read", "write"]
