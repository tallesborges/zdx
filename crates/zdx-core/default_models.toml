# Generated by zdx models update
# Edit this file to customize the model picker.

[[model]]
id = "claude-opus-4-6"
provider = "anthropic"
display_name = "Claude Opus 4.6"
context_limit = 200000

[model.pricing]
input = 5.0
output = 25.0
cache_read = 0.5
cache_write = 6.25

[model.capabilities]
reasoning = true
input_images = true
output_limit = 128000

[[model]]
id = "claude-opus-4-5"
provider = "anthropic"
display_name = "Claude Opus 4.5"
context_limit = 200000

[model.pricing]
input = 5.0
output = 25.0
cache_read = 0.5
cache_write = 6.25

[model.capabilities]
reasoning = true
input_images = true
output_limit = 64000

[[model]]
id = "claude-sonnet-4-5"
provider = "anthropic"
display_name = "Claude Sonnet 4.5"
context_limit = 200000

[model.pricing]
input = 3.0
output = 15.0
cache_read = 0.3
cache_write = 3.75

[model.capabilities]
reasoning = true
input_images = true
output_limit = 64000

[[model]]
id = "claude-haiku-4-5"
provider = "anthropic"
display_name = "Claude Haiku 4.5"
context_limit = 200000

[model.pricing]
input = 1.0
output = 5.0
cache_read = 0.1
cache_write = 1.25

[model.capabilities]
reasoning = true
input_images = true
output_limit = 64000

[[model]]
id = "claude-cli:claude-opus-4-6"
provider = "claude-cli"
display_name = "Claude Opus 4.6"
context_limit = 200000

[model.pricing]
input = 5.0
output = 25.0
cache_read = 0.5
cache_write = 6.25

[model.capabilities]
reasoning = true
input_images = true
output_limit = 128000

[[model]]
id = "claude-cli:claude-opus-4-5"
provider = "claude-cli"
display_name = "Claude Opus 4.5"
context_limit = 200000

[model.pricing]
input = 5.0
output = 25.0
cache_read = 0.5
cache_write = 6.25

[model.capabilities]
reasoning = true
input_images = true
output_limit = 64000

[[model]]
id = "claude-cli:claude-sonnet-4-5"
provider = "claude-cli"
display_name = "Claude Sonnet 4.5"
context_limit = 200000

[model.pricing]
input = 3.0
output = 15.0
cache_read = 0.3
cache_write = 3.75

[model.capabilities]
reasoning = true
input_images = true
output_limit = 64000

[[model]]
id = "claude-cli:claude-haiku-4-5"
provider = "claude-cli"
display_name = "Claude Haiku 4.5"
context_limit = 200000

[model.pricing]
input = 1.0
output = 5.0
cache_read = 0.1
cache_write = 1.25

[model.capabilities]
reasoning = true
input_images = true
output_limit = 64000

[[model]]
id = "openai:gpt-5.3-codex"
provider = "openai"
display_name = "GPT-5.3 Codex"
context_limit = 400000

[model.pricing]
input = 1.75
output = 14.0
cache_read = 0.175
cache_write = 0.0

[model.capabilities]
reasoning = true
input_images = true
output_limit = 128000

[[model]]
id = "openai:gpt-5.3-codex-spark"
provider = "openai"
display_name = "GPT-5.3 Codex Spark"
context_limit = 128000

[model.pricing]
input = 1.75
output = 14.0
cache_read = 0.175
cache_write = 0.0

[model.capabilities]
reasoning = true
input_images = true
output_limit = 32000

[[model]]
id = "openai:gpt-5.2-codex"
provider = "openai"
display_name = "GPT-5.2 Codex"
context_limit = 400000

[model.pricing]
input = 1.75
output = 14.0
cache_read = 0.175
cache_write = 0.0

[model.capabilities]
reasoning = true
input_images = true
output_limit = 128000

[[model]]
id = "openai:gpt-5.1-codex-max"
provider = "openai"
display_name = "GPT-5.1 Codex Max"
context_limit = 400000

[model.pricing]
input = 1.25
output = 10.0
cache_read = 0.125
cache_write = 0.0

[model.capabilities]
reasoning = true
input_images = true
output_limit = 128000

[[model]]
id = "gpt-5.3-codex"
provider = "openai-codex"
display_name = "GPT-5.3 Codex"
context_limit = 400000

[model.pricing]
input = 1.75
output = 14.0
cache_read = 0.175
cache_write = 0.0

[model.capabilities]
reasoning = true
input_images = true
output_limit = 128000

[[model]]
id = "gpt-5.3-codex-spark"
provider = "openai-codex"
display_name = "GPT-5.3 Codex Spark"
context_limit = 128000

[model.pricing]
input = 1.75
output = 14.0
cache_read = 0.175
cache_write = 0.0

[model.capabilities]
reasoning = true
input_images = true
output_limit = 32000

[[model]]
id = "gpt-5.2-codex"
provider = "openai-codex"
display_name = "GPT-5.2 Codex"
context_limit = 400000

[model.pricing]
input = 1.75
output = 14.0
cache_read = 0.175
cache_write = 0.0

[model.capabilities]
reasoning = true
input_images = true
output_limit = 128000

[[model]]
id = "gpt-5.1-codex-max"
provider = "openai-codex"
display_name = "GPT-5.1 Codex Max"
context_limit = 400000

[model.pricing]
input = 1.25
output = 10.0
cache_read = 0.125
cache_write = 0.0

[model.capabilities]
reasoning = true
input_images = true
output_limit = 128000

[[model]]
id = "openrouter:deepseek/deepseek-v3.1-terminus:exacto"
provider = "openrouter"
display_name = "DeepSeek V3.1 Terminus (exacto)"
context_limit = 131072

[model.pricing]
input = 0.27
output = 1.0
cache_read = 0.0
cache_write = 0.0

[model.capabilities]
reasoning = true
input_images = false
output_limit = 65536

[[model]]
id = "openrouter:moonshotai/kimi-k2-0905:exacto"
provider = "openrouter"
display_name = "Kimi K2 Instruct 0905 (exacto)"
context_limit = 262144

[model.pricing]
input = 0.6
output = 2.5
cache_read = 0.0
cache_write = 0.0

[model.capabilities]
reasoning = false
input_images = false
output_limit = 16384

[[model]]
id = "openrouter:openai/gpt-oss-120b:exacto"
provider = "openrouter"
display_name = "GPT OSS 120B (exacto)"
context_limit = 131072

[model.pricing]
input = 0.05
output = 0.24
cache_read = 0.0
cache_write = 0.0

[model.capabilities]
reasoning = true
input_images = false
output_limit = 32768

[[model]]
id = "openrouter:qwen/qwen3-coder:exacto"
provider = "openrouter"
display_name = "Qwen3 Coder (exacto)"
context_limit = 131072

[model.pricing]
input = 0.38
output = 1.53
cache_read = 0.0
cache_write = 0.0

[model.capabilities]
reasoning = false
input_images = false
output_limit = 32768

[[model]]
id = "openrouter:z-ai/glm-4.6:exacto"
provider = "openrouter"
display_name = "GLM 4.6 (exacto)"
context_limit = 200000

[model.pricing]
input = 0.6
output = 1.9
cache_read = 0.11
cache_write = 0.0

[model.capabilities]
reasoning = true
input_images = false
output_limit = 128000

[[model]]
id = "moonshot:kimi-k2.5"
provider = "moonshot"
display_name = "Kimi K2.5"
context_limit = 262144

[model.pricing]
input = 0.6
output = 3.0
cache_read = 0.1
cache_write = 0.0

[model.capabilities]
reasoning = true
input_images = true
output_limit = 262144

[[model]]
id = "stepfun:step-3.5-flash"
provider = "stepfun"
display_name = "Step 3.5 Flash"
context_limit = 256000

[model.pricing]
input = 0.096
output = 0.288
cache_read = 0.019
cache_write = 0.0

[model.capabilities]
reasoning = true
input_images = false
output_limit = 256000

[[model]]
id = "mimo:mimo-v2-flash"
provider = "mimo"
display_name = "MiMo-V2-Flash"
context_limit = 256000

[model.pricing]
input = 0.07
output = 0.21
cache_read = 0.0
cache_write = 0.0

[model.capabilities]
reasoning = true
input_images = false
output_limit = 32000

[[model]]
id = "gemini:gemini-3.1-pro-preview-customtools"
provider = "gemini"
display_name = "Gemini 3.1 Pro Preview Custom Tools"
context_limit = 1048576

[model.pricing]
input = 2.0
output = 12.0
cache_read = 0.2
cache_write = 0.0

[model.capabilities]
reasoning = true
input_images = true
output_limit = 65536

[[model]]
id = "gemini:gemini-3.1-pro-preview"
provider = "gemini"
display_name = "Gemini 3.1 Pro Preview"
context_limit = 1048576

[model.pricing]
input = 2.0
output = 12.0
cache_read = 0.2
cache_write = 0.0

[model.capabilities]
reasoning = true
input_images = true
output_limit = 65536

[[model]]
id = "gemini:gemini-3-flash-preview"
provider = "gemini"
display_name = "Gemini 3 Flash Preview"
context_limit = 1048576

[model.pricing]
input = 0.5
output = 3.0
cache_read = 0.05
cache_write = 0.0

[model.capabilities]
reasoning = true
input_images = true
output_limit = 65536

[[model]]
id = "gemini:gemini-3-pro-preview"
provider = "gemini"
display_name = "Gemini 3 Pro Preview"
context_limit = 1000000

[model.pricing]
input = 2.0
output = 12.0
cache_read = 0.2
cache_write = 0.0

[model.capabilities]
reasoning = true
input_images = true
output_limit = 64000

[[model]]
id = "gemini:gemini-2.5-flash"
provider = "gemini"
display_name = "Gemini 2.5 Flash"
context_limit = 1048576

[model.pricing]
input = 0.3
output = 2.5
cache_read = 0.075
cache_write = 0.0

[model.capabilities]
reasoning = true
input_images = true
output_limit = 65536

[[model]]
id = "gemini:gemini-2.5-flash-lite"
provider = "gemini"
display_name = "Gemini 2.5 Flash Lite"
context_limit = 1048576

[model.pricing]
input = 0.1
output = 0.4
cache_read = 0.025
cache_write = 0.0

[model.capabilities]
reasoning = true
input_images = true
output_limit = 65536

[[model]]
id = "gemini-cli:gemini-3.1-pro-preview-customtools"
provider = "gemini-cli"
display_name = "Gemini 3.1 Pro Preview Custom Tools"
context_limit = 1048576

[model.pricing]
input = 2.0
output = 12.0
cache_read = 0.2
cache_write = 0.0

[model.capabilities]
reasoning = true
input_images = true
output_limit = 65536

[[model]]
id = "gemini-cli:gemini-3.1-pro-preview"
provider = "gemini-cli"
display_name = "Gemini 3.1 Pro Preview"
context_limit = 1048576

[model.pricing]
input = 2.0
output = 12.0
cache_read = 0.2
cache_write = 0.0

[model.capabilities]
reasoning = true
input_images = true
output_limit = 65536

[[model]]
id = "gemini-cli:gemini-3-flash-preview"
provider = "gemini-cli"
display_name = "Gemini 3 Flash Preview"
context_limit = 1048576

[model.pricing]
input = 0.5
output = 3.0
cache_read = 0.05
cache_write = 0.0

[model.capabilities]
reasoning = true
input_images = true
output_limit = 65536

[[model]]
id = "gemini-cli:gemini-3-pro-preview"
provider = "gemini-cli"
display_name = "Gemini 3 Pro Preview"
context_limit = 1000000

[model.pricing]
input = 2.0
output = 12.0
cache_read = 0.2
cache_write = 0.0

[model.capabilities]
reasoning = true
input_images = true
output_limit = 64000

[[model]]
id = "gemini-cli:gemini-2.5-flash"
provider = "gemini-cli"
display_name = "Gemini 2.5 Flash"
context_limit = 1048576

[model.pricing]
input = 0.3
output = 2.5
cache_read = 0.075
cache_write = 0.0

[model.capabilities]
reasoning = true
input_images = true
output_limit = 65536

[[model]]
id = "gemini-cli:gemini-2.5-flash-lite"
provider = "gemini-cli"
display_name = "Gemini 2.5 Flash Lite"
context_limit = 1048576

[model.pricing]
input = 0.1
output = 0.4
cache_read = 0.025
cache_write = 0.0

[model.capabilities]
reasoning = true
input_images = true
output_limit = 65536

[[model]]
id = "zen:big-pickle"
provider = "zen"
display_name = "Big Pickle"
context_limit = 200000

[model.pricing]
input = 0.0
output = 0.0
cache_read = 0.0
cache_write = 0.0

[model.capabilities]
reasoning = true
input_images = false
output_limit = 128000
api = "anthropic-messages"

[[model]]
id = "zen:gemini-3-flash"
provider = "zen"
display_name = "Gemini 3 Flash"
context_limit = 1048576

[model.pricing]
input = 0.5
output = 3.0
cache_read = 0.05
cache_write = 0.0

[model.capabilities]
reasoning = true
input_images = true
output_limit = 65536
api = "google-generative-ai"

[[model]]
id = "zen:minimax-m2.5"
provider = "zen"
display_name = "MiniMax M2.5"
context_limit = 204800

[model.pricing]
input = 0.3
output = 1.2
cache_read = 0.06
cache_write = 0.0

[model.capabilities]
reasoning = true
input_images = false
output_limit = 131072
api = "openai-completions"

[[model]]
id = "zen:minimax-m2.5-free"
provider = "zen"
display_name = "MiniMax M2.5 Free"
context_limit = 204800

[model.pricing]
input = 0.0
output = 0.0
cache_read = 0.0
cache_write = 0.0

[model.capabilities]
reasoning = true
input_images = false
output_limit = 131072
api = "anthropic-messages"

[[model]]
id = "zen:kimi-k2.5"
provider = "zen"
display_name = "Kimi K2.5"
context_limit = 262144

[model.pricing]
input = 0.6
output = 3.0
cache_read = 0.08
cache_write = 0.0

[model.capabilities]
reasoning = true
input_images = true
output_limit = 262144
api = "openai-completions"

[[model]]
id = "zen:kimi-k2.5-free"
provider = "zen"
display_name = "Kimi K2.5 Free"
context_limit = 262144

[model.pricing]
input = 0.0
output = 0.0
cache_read = 0.0
cache_write = 0.0

[model.capabilities]
reasoning = true
input_images = true
output_limit = 262144
api = "openai-completions"

[[model]]
id = "zen:glm-5"
provider = "zen"
display_name = "GLM-5"
context_limit = 204800

[model.pricing]
input = 1.0
output = 3.2
cache_read = 0.2
cache_write = 0.0

[model.capabilities]
reasoning = true
input_images = false
output_limit = 131072
api = "openai-completions"

[[model]]
id = "zen:glm-5-free"
provider = "zen"
display_name = "GLM-5 Free"
context_limit = 204800

[model.pricing]
input = 0.0
output = 0.0
cache_read = 0.0
cache_write = 0.0

[model.capabilities]
reasoning = true
input_images = false
output_limit = 131072
api = "openai-completions"

[[model]]
id = "minimax:MiniMax-M2.5"
provider = "minimax"
display_name = "MiniMax-M2.5"
context_limit = 204800

[model.pricing]
input = 0.3
output = 1.2
cache_read = 0.03
cache_write = 0.375

[model.capabilities]
reasoning = true
input_images = false
output_limit = 131072

[[model]]
id = "minimax:MiniMax-M2.1"
provider = "minimax"
display_name = "MiniMax-M2.1"
context_limit = 204800

[model.pricing]
input = 0.3
output = 1.2
cache_read = 0.0
cache_write = 0.0

[model.capabilities]
reasoning = true
input_images = false
output_limit = 131072

[[model]]
id = "zai:glm-5"
provider = "zai"
display_name = "GLM-5"
context_limit = 204800

[model.pricing]
input = 1.0
output = 3.2
cache_read = 0.2
cache_write = 0.0

[model.capabilities]
reasoning = true
input_images = false
output_limit = 131072

[[model]]
id = "zai:glm-4.7"
provider = "zai"
display_name = "GLM-4.7"
context_limit = 204800

[model.pricing]
input = 0.6
output = 2.2
cache_read = 0.11
cache_write = 0.0

[model.capabilities]
reasoning = true
input_images = false
output_limit = 131072

[[model]]
id = "zai:glm-4.7-flash"
provider = "zai"
display_name = "GLM-4.7-Flash"
context_limit = 200000

[model.pricing]
input = 0.0
output = 0.0
cache_read = 0.0
cache_write = 0.0

[model.capabilities]
reasoning = true
input_images = false
output_limit = 131072

[[model]]
id = "xai:grok-4-1-fast-non-reasoning"
provider = "xai"
display_name = "Grok 4.1 Fast (Non-Reasoning)"
context_limit = 2000000

[model.pricing]
input = 0.2
output = 0.5
cache_read = 0.05
cache_write = 0.0

[model.capabilities]
reasoning = false
input_images = true
output_limit = 30000

[[model]]
id = "xai:grok-4-1-fast"
provider = "xai"
display_name = "Grok 4.1 Fast"
context_limit = 2000000

[model.pricing]
input = 0.2
output = 0.5
cache_read = 0.05
cache_write = 0.0

[model.capabilities]
reasoning = true
input_images = true
output_limit = 30000

[[model]]
id = "xai:grok-code-fast-1"
provider = "xai"
display_name = "Grok Code Fast 1"
context_limit = 256000

[model.pricing]
input = 0.2
output = 1.5
cache_read = 0.02
cache_write = 0.0

[model.capabilities]
reasoning = true
input_images = false
output_limit = 10000
