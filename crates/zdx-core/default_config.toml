# ZDX Configuration
#
# This file is auto-generated. Edit as needed.
# Documentation: https://github.com/tallesborges/zdx#configuration

# The Claude model to use
model = "claude-haiku-4-5"

# Maximum tokens for responses (optional)
# Defaults to the model's output limit (exclusive, minus 1) when unset.
# max_tokens = 12288

# Timeout for tool execution in seconds (0 disables timeout)
tool_timeout_secs = 0

# System prompt (inline)
# system_prompt = "You are a helpful coding assistant."

# System prompt from file (takes precedence over inline)
# system_prompt_file = "/path/to/system_prompt.md"

# Extended thinking level
# Controls how much reasoning the model shows before responding.
# Higher levels allocate more output tokens to reasoning.
# Options: off, minimal (~5%), low (~20%), medium (~50%), high (~80%), xhigh (~95%)
# Note: when max_tokens is set, it is auto-adjusted to ensure room for both thinking and response.
thinking_level = "off"
handoff_model = "gemini-cli:gemini-3-flash-preview"
title_model = "gemini-cli:gemini-2.5-flash"

# Model used for handoff generation subagent.
# Examples: "gemini-cli:gemini-2.5-flash", "openai:gpt-5.2"
# handoff_model = "gemini-cli:gemini-2.5-flash"

# Model used for auto-title generation subagent.
# Examples: "gemini-cli:gemini-2.5-flash", "openai:gpt-5.2"
# title_model = "gemini-cli:gemini-2.5-flash"

# Skill discovery configuration
# Enable/disable skill sources (all enabled by default)
[skills]
[skills.sources]
zdx_user = "on"
zdx_project = "on"
codex_user = "on"
claude_user = "on"
claude_project = "on"
agents_user = "on"
agents_project = "on"
# GitHub repositories containing skills (owner/repo/path)
skill_repositories = ["openai/skills/skills/.curated", "openai/skills/skills/.system", "anthropics/skills/skills"]
# ignored_skills = ["test-*", "wip-*"]
# include_skills = ["deploy-*", "release-*"]

# Telegram bot configuration
[telegram]
# bot_token = "123456789:abcDEF..."
# allowlist_user_ids = [123456789]
# bot_token can also be set via ZDX_TELEGRAM_BOT_TOKEN
# Model used by the Telegram bot
model = "claude-cli:claude-opus-4-6"
# Thinking level used by the Telegram bot
thinking_level = "minimal"

# Telegram audio transcription configuration
# provider: Transcription provider to use ("openai" or "mistral", defaults to auto-detect)
# model: Model to use for transcription (provider-specific, defaults to "whisper-1" for OpenAI, "voxtral-mini-latest" for Mistral)
# language: Optional language hint (ISO 639-1 code like "en", "pt", "es") for better accuracy
[telegram.transcription]
# provider = "openai"
# model = "whisper-1"
# language = "en"

# OpenAI reasoning effort (used by Codex models).
# Options: low, medium, high, xhigh

# Provider configuration.
# api_key: Optional API key (overrides environment variable)
# base_url: Optional base URL (for proxies or test rigs)
# tools: Optional list of enabled tools. If set, overrides the default tool set.
#
# Available tools: bash, apply_patch, edit, read, read_thread, write
# Default tool sets:
#   - default:       ["bash", "edit", "read", "read_thread", "write"]
#   - openai_codex:  ["bash", "apply_patch", "read", "read_thread"]

[providers.anthropic]
enabled = true
# api_key = "sk-ant-..."  # Overrides ANTHROPIC_API_KEY env var
# base_url = "https://api.anthropic.com"
models = ["claude-opus-4-6", "claude-opus-4-5", "claude-sonnet-4-5", "claude-haiku-4-5"]

[providers.claude_cli]
enabled = true
# base_url = "https://api.anthropic.com"
models = ["claude-opus-4-6", "claude-opus-4-5", "claude-sonnet-4-5", "claude-haiku-4-5"]

[providers.openai]
enabled = true
# api_key = "sk-..."  # Overrides OPENAI_API_KEY env var
# base_url = "https://api.openai.com/v1"
models = ["gpt-5.2", "gpt-5.1", "gpt-5-mini", "gpt-5-nano", "gpt-5.2-codex", "gpt-5.1-codex-max", "gpt-5.1-codex-mini", "gpt-4.1"]

[providers.openai_codex]
enabled = true
models = ["gpt-5.3-codex", "gpt-5.2-codex", "gpt-5.1-codex-max", "gpt-5.1-codex-mini", "gpt-5.2"]
# Codex models have built-in apply_patch instructions

[providers.openrouter]
enabled = true
# api_key = "sk-or-..."  # Overrides OPENROUTER_API_KEY env var
# base_url = "https://openrouter.ai/api/v1"
models = ["*:exacto"]

[providers.moonshot]
enabled = true
# api_key = "sk-..."  # Overrides MOONSHOT_API_KEY env var
# base_url = "https://api.moonshot.ai/v1"
models = ["kimi-k2.5"]

[providers.stepfun]
enabled = true
# api_key = "sk-..."  # Overrides STEPFUN_API_KEY env var
# base_url = "https://api.stepfun.ai/v1"
models = ["step-3.5-flash"]

[providers.mimo]
enabled = true
# api_key = "sk-..."  # Overrides MIMO_API_KEY env var
# base_url = "https://api.xiaomimimo.com/v1"
models = ["mimo-v2-flash"]

[providers.gemini]
enabled = true
# api_key = "..."  # Overrides GEMINI_API_KEY env var
# base_url = "https://generativelanguage.googleapis.com/v1beta"
models = ["gemini-3-flash-preview", "gemini-3-pro-preview", "gemini-2.5-flash", "gemini-2.5-flash-lite"]

[providers.gemini_cli]
enabled = true
# base_url = "https://cloudcode-pa.googleapis.com"
models = ["gemini-3-flash-preview", "gemini-3-pro-preview", "gemini-2.5-flash", "gemini-2.5-flash-lite"]

[providers.mistral]
enabled = true
# api_key = "..."  # Overrides MISTRAL_API_KEY env var
# base_url = "https://api.mistral.ai/v1"
models = ["voxtral-mini-latest"]
