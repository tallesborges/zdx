# ZDX Configuration
#
# This file is auto-generated. Edit as needed.
# Documentation: https://github.com/tallesborges/zdx#configuration

# The Claude model to use
model = "claude-haiku-4-5"

# Maximum tokens for responses (optional)
# Defaults to the model's output limit (exclusive, minus 1) when unset.
# max_tokens = 12288

# Timeout for tool execution in seconds (0 disables timeout)
tool_timeout_secs = 0
handoff_model = "gemini-cli:gemini-3-flash-preview"
title_model = "gemini-cli:gemini-2.5-flash"
thinking_level = "off"

# System prompt (inline)
# system_prompt = "You are a helpful coding assistant."

# System prompt from file (takes precedence over inline)
# system_prompt_file = "/path/to/system_prompt.md"

# Optional custom system prompt template file.
# zdx always renders a MiniJinja system prompt template.
# If this file is unset (default), zdx uses the built-in template.
# MiniJinja syntax supported: {{ var }}, {% if %}, {% for %}
# Useful vars: invocation_term, invocation_term_plural,
# is_openai_codex, base_prompt, project_context,
# skills_list, subagents_config, cwd, date
[prompt_template]
# file = "prompts/system_prompt_template.md"

# Extended thinking level
# Controls how much reasoning the model shows before responding.
# Higher levels allocate more output tokens to reasoning.
# Options: off, minimal (~5%), low (~20%), medium (~50%), high (~80%), xhigh (~95%)
# Note: when max_tokens is set, it is auto-adjusted to ensure room for both thinking and response.
thinking_level = "off"
handoff_model = "gemini-cli:gemini-3-flash-preview"
title_model = "gemini-cli:gemini-2.5-flash"

# Subagent delegation configuration
# enabled: Expose invoke_subagent tool to the model.
# available_models: Auto-populated from enabled providers + model registry (TUI picker source).
[subagents]
enabled = true

# Model used for handoff generation subagent.
# Examples: "gemini-cli:gemini-2.5-flash", "openai:gpt-5.2"
# handoff_model = "gemini-cli:gemini-2.5-flash"

# Model used for auto-title generation subagent.
# Examples: "gemini-cli:gemini-2.5-flash", "openai:gpt-5.2"
# title_model = "gemini-cli:gemini-2.5-flash"

# Skill discovery configuration
# Enable/disable skill sources (all enabled by default)
[skills]
skill_repositories = [
  "openai/skills/skills/.curated",
  "openai/skills/skills/.system",
  "anthropics/skills/skills",
]
[skills.sources]
zdx_user = true
zdx_project = true
codex_user = true
claude_user = true
claude_project = true
agents_user = true
agents_project = true
# GitHub repositories containing skills (owner/repo/path)
# ignored_skills = ["test-*", "wip-*"]
# include_skills = ["deploy-*", "release-*"]

# Telegram bot configuration
[telegram]
# bot_token = "123456789:abcDEF..."
# allowlist_user_ids = [123456789]
# bot_token can also be set via ZDX_TELEGRAM_BOT_TOKEN
# Model used by the Telegram bot
model = "claude-cli:claude-opus-4-6"
# Thinking level used by the Telegram bot
thinking_level = "minimal"

# Telegram audio transcription configuration
# provider: Transcription provider to use ("openai" or "mistral", defaults to auto-detect)
# model: Model to use for transcription (provider-specific, defaults to "whisper-1" for OpenAI, "voxtral-mini-latest" for Mistral)
# language: Optional language hint (ISO 639-1 code like "en", "pt", "es") for better accuracy
[telegram.transcription]
# provider = "openai"
# model = "whisper-1"
# language = "en"

# OpenAI reasoning effort (used by Codex models).
# Options: low, medium, high, xhigh

# Provider configuration.
# api_key: Optional API key (overrides environment variable)
# base_url: Optional base URL (for proxies or test rigs)
# tools: Optional list of enabled tools. If set, overrides the default tool set.
#
# Available tools: bash, apply_patch, edit, fetch_webpage, invoke_subagent, read, read_thread, thread_search, web_search, write
# Default tool sets:
#   - default:       ["bash", "edit", "fetch_webpage", "invoke_subagent", "read", "read_thread", "thread_search", "web_search", "write"]
#   - openai_codex:  ["bash", "apply_patch", "fetch_webpage", "invoke_subagent", "read", "read_thread", "thread_search", "web_search"]

[providers.anthropic]
enabled = true
# api_key = "sk-ant-..."  # Overrides ANTHROPIC_API_KEY env var
# base_url = "https://api.anthropic.com"
models = [
  "claude-opus-4-6",
  "claude-opus-4-5",
  "claude-sonnet-4-5",
  "claude-haiku-4-5",
]

[providers.claude_cli]
enabled = true
# base_url = "https://api.anthropic.com"
models = [
  "claude-opus-4-6",
  "claude-opus-4-5",
  "claude-sonnet-4-5",
  "claude-haiku-4-5",
]

[providers.openai]
enabled = true
# api_key = "sk-..."  # Overrides OPENAI_API_KEY env var
# base_url = "https://api.openai.com/v1"
models = [
  "gpt-5.3-codex",
  "gpt-5.3-codex-spark",
  "gpt-5.2-codex",
  "gpt-5.1-codex-max",
]

[providers.openai_codex]
enabled = true
models = [
  "gpt-5.3-codex",
  "gpt-5.3-codex-spark",
  "gpt-5.2-codex",
  "gpt-5.1-codex-max",
]
# Codex models have built-in apply_patch instructions

[providers.openrouter]
enabled = true
# api_key = "sk-or-..."  # Overrides OPENROUTER_API_KEY env var
# base_url = "https://openrouter.ai/api/v1"
models = ["*:exacto"]

[providers.moonshot]
enabled = true
# api_key = "sk-..."  # Overrides MOONSHOT_API_KEY env var
# base_url = "https://api.moonshot.ai/v1"
models = ["kimi-k2.5"]

[providers.stepfun]
enabled = true
# api_key = "sk-..."  # Overrides STEPFUN_API_KEY env var
# base_url = "https://api.stepfun.ai/v1"
models = ["step-3.5-flash"]

[providers.mimo]
enabled = true
# api_key = "sk-..."  # Overrides MIMO_API_KEY env var
# base_url = "https://api.xiaomimimo.com/v1"
models = ["mimo-v2-flash"]

[providers.gemini]
enabled = true
# api_key = "..."  # Overrides GEMINI_API_KEY env var
# base_url = "https://generativelanguage.googleapis.com/v1beta"
models = [
  "gemini-3-flash-preview",
  "gemini-3-pro-preview",
  "gemini-2.5-flash",
  "gemini-2.5-flash-lite",
]

[providers.gemini_cli]
enabled = true
# base_url = "https://cloudcode-pa.googleapis.com"
models = [
  "gemini-3-flash-preview",
  "gemini-3-pro-preview",
  "gemini-2.5-flash",
  "gemini-2.5-flash-lite",
]

[providers.mistral]
enabled = true
# api_key = "..."  # Overrides MISTRAL_API_KEY env var
# base_url = "https://api.mistral.ai/v1"
models = ["voxtral-mini-latest"]
